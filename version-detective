#!/usr/bin/env python
# Use static files and git to work out a web application's middleware version
# Credit to https://github.com/cornerpirate/git-version for the core idea

import argparse, os, sys, re, subprocess, requests, difflib, json
from git import Repo

class VersionDetective:
 
  def __init__( self, url, settings ):
    if 'webroot' not in settings.keys(): settings['webroot'] = ''
    self.settings = settings
    self.url = url
    self.head_id = None

  # Clone a repo / branch
  def clone( self ):
    
    print 'Using git URL: ' + self.settings['git']
    repo_name = self.settings['git'].split('/')[-1].replace('.git','')
    if 'branch' in self.settings.keys():
      repo_name += self.settings['branch']
      branch = self.settings['branch']
    else:
      branch = 'master'

    # Make repos dir under the dir of this script
    repo_dir = os.path.dirname(os.path.realpath(__file__)) + '/repos/' + repo_name
    if os.path.isdir( repo_dir ):
      print repo_dir + ' already exists'
      p = subprocess.Popen(['git','pull','origin', branch], stdout=subprocess.PIPE, cwd=repo_dir, universal_newlines=False)
    else:
      print 'Making dir ' + repo_dir
      os.makedirs( repo_dir )
      print 'Cloning ' + self.settings['git'] + ' into '+repo_dir+'...'
      p = subprocess.Popen(['git','clone',self.settings['git'], repo_dir], stdout=subprocess.PIPE, universal_newlines=False)
    
    self.working_dir = repo_dir
    while True:
      line = p.stdout.readline().rstrip()
      if not line:
        break
      print line

    return True


  def get_most_recent_matching_commit( self, fname ):
    
    print ''
    print 'Finding a matching commit for ' + fname
    
    # furl = self.url + '/' + self.settings['webroot'] + '/' + fname
    furl = self.get_file_url( fname )
    if not furl: return False

    # Get remote file content
    r = requests.get(furl)
    remotecontent = r.text.splitlines()

    # Get list of commits relating to this file
    # git log --pretty=format:"%H" index.php
    p = subprocess.Popen(['git','log','--pretty=format:"%H"',fname], stdout=subprocess.PIPE, cwd=self.working_dir, universal_newlines=False)
    out, err = p.communicate()
    commits = out.splitlines()

    for c in commits:
      # git show 5322be300a27460ae28fb79772d55f946179c84c:index.php
      c = c.replace('"','')
      print c + ':' + fname
      p = subprocess.Popen(['git','show',c+':'+fname], stdout=subprocess.PIPE, cwd=self.working_dir, universal_newlines=False)
      out, err = p.communicate()
      content = out.splitlines()
  
      try:
        diff = difflib.unified_diff(remotecontent,content)
        lines = []
        for d in diff:
          lines.append(str(d))
        if len( lines ) == 0:
          return c
      except:
        continue
    return False

  def get_head_id( self ):
    if self.head_id:
      return self.head_id
    p = subprocess.Popen(['git','rev-parse','HEAD'], stdout=subprocess.PIPE, cwd=self.working_dir, universal_newlines=False)
    out, err = p.communicate()
    self.head_id = out.strip()
    return self.head_id

  def get_file_url( self, filepath ):
    wr = self.settings['webroot']
    if wr != '':
      if not filepath.startswith( wr ):
        return False
      else:
        filepath = filepath.replace( wr, '' )
    return self.url + '/' + filepath
      

  def analyse( self ):
    
    # Clone repo
    if not self.clone():
      print 'clone / pull failed. Quitting'
      return False

    # Produce list of static files from git log

    print 'Building static files index...'
    filesregex = r'\.(txt|md|js|css|html|xml)$'

    pipes = []
    pipes.append(['git','log','--name-status','--diff-filter=AM'])
    pipes.append(['grep','^\(commit\|A\|M\)\W'])
    procs = []
    for p in pipes:
      
      # Any stdout available?
      if len( procs ) > 0:
        out = procs[-1].stdout
      else:
        out = None

      procs.append( subprocess.Popen(p, stdout=subprocess.PIPE, cwd=self.working_dir, stdin=out, universal_newlines=False) )

    out,err = procs[-1].communicate()

    staticfiles = []

    commit = None
    for line in out.splitlines():
      m = re.match('commit\W+(\w+)',line)
      if m:
        commit = m.group(1)
        continue
      m = re.match('[AM]\W+(.+)', line)
      if m:
        fname = m.group(1)
        if 'webroot' in self.settings.keys() and not re.match( self.settings['webroot'], fname ): continue
        if re.search( filesregex, fname, re.IGNORECASE ):
          if fname not in staticfiles:
            staticfiles.append(fname)
   
    validcommits = {}
    missing = {}
    filecount = 0
    print str(len(staticfiles)) + ' static files found'
    for f in staticfiles:
      if filecount >= 10: break
      # furl = self.url + '/' + f.replace(self.settings['webroot'],'')
      furl = self.get_file_url( f )
      if not furl: continue
      print furl,
      r = requests.head(furl)
      print r.status_code
      if r.status_code == 200:
       
        # Get 
        commit = self.get_most_recent_matching_commit( f )
        if commit:
          print 'MATCH in: ' + commit
          print ''
          if commit not in validcommits.keys(): validcommits[commit] = []
          validcommits[commit].append(furl)
          filecount += 1
        else:
          print 'NO MATCH'
          print ''

      # record missing files
      elif r.status_code == 404 and len(validcommits) == 0:
        if commit not in missing.keys(): missing[commit] = []
        missing[commit] = furl
      
    # Get dates for each of these commits
    dates = {}
    for c in validcommits.keys():
      p = subprocess.Popen(['git','show','-s','--format=%ci',c], stdout=subprocess.PIPE, cwd=self.working_dir, universal_newlines=False)
      out, err = p.communicate()
      date = out.strip()
      dates[date] = c
    
    dks = dates.keys()
    dks.sort( reverse=True )
    print ''
    print 'Found files matching these commits:'
    mostrecent = None
    for d in dks:
      if not mostrecent: 
        mostrecent = d
        currentcommit = dates[d]
      c = dates[d]
      print ''
      print d + ': ' + c + ' ('+str(len(validcommits[c]))+' matching files)'
      for f in validcommits[c]:
        print ' - ' + f
    
    print ''
    print 'Version Detective concludes that ' + self.url + ' is probably running code no older than ' + mostrecent

    # Is this the current head?
    if currentcommit == self.get_head_id():
      print 'This is the current HEAD commit (most up to date)'
    else:
      p = subprocess.Popen(['git','diff','--name-only', currentcommit, 'HEAD'], stdout=subprocess.PIPE, cwd=self.working_dir, universal_newlines=False)
      changedfiles = p.communicate()[0].splitlines()
      print 'This is not the current HEAD commit. '+str(len(changedfiles))+' files were changed between this and the current HEAD.'
      

      # Were any static files changed between current commit and HEAD? If not, current commit could be HEAD
      changedstatic = []
      for f in changedfiles:
        f = f.strip()
        if re.search( filesregex, f ): changedstatic.append(f)

      if len( changedstatic ) == 0:
        print 'Note that no static files were changed between the current commit and HEAD, so the remote commit could be HEAD, just not detectable through static file analysis.'

      print ''
      print 'More details:'
      print ' - List files changed between commits: git --git-dir='+self.working_dir+'/.git diff --name-only ' + currentcommit + ' HEAD'
      print ' - Complete diff between versions: git --git-dir='+self.working_dir+'/.git diff ' + currentcommit + ' HEAD'
      print ' - Diff of just changes in PHP files: git --git-dir='+self.working_dir+'/.git diff ' + currentcommit + ' HEAD -- \'*.php\''
      print ' - Changelog between versions: git --git-dir='+self.working_dir+'/.git log --name-status ' + currentcommit + '...HEAD'
    return


def main():
  
  # Command line options
  parser = argparse.ArgumentParser(description="Determine a site's middleware version through analysis of it's static files")
  
  # Tool configuration
  parser.add_argument("-m", "--middleware", help="Middleware project to check out")
  parser.add_argument("-l", "--list-middleware", action="store_true", help="List middleware that Version Detective knows about")
  parser.add_argument("-g", "--git", help="Check out this git URL to analyse (if not using --middleware)")
  parser.add_argument("-b", "--branch", help="Which branch of the git repo to use (if not using --middleware)")
  parser.add_argument("-w", "--webroot", help="Directory within the project which corresponds to the web root for static files (if not using --middleware)")
  parser.add_argument("-u", "--url", help="URL of site to compare against")
  args = parser.parse_args()
  
  if len( sys.argv)==1:
    parser.print_help()
    return

  # Projects and where their web root is
  with open('middleware.json') as f:
    middleware = json.loads(f.read())

  if args.list_middleware:
    print 'Known middleware:'
    for key, item in middleware.iteritems():
      print key + ' ('+item['git'],
      if 'branch' in item.keys():
        print ':' + item['branch'],
      print ')'
    return

  if not args.url:
    print 'Requires a target URL --url'
    return
  
  if args.middleware and args.middleware in middleware.keys():
    settings = middleware[args.middleware]
  elif not args.git:
    print 'Requires at least --git or --middleware'
    return
  else:
    settings = {}

  if args.git:
    settings['git'] = args.git
  
  if args.branch:
    settings['branch'] = args.branch
  
  if args.webroot:
    settings['webroot'] = args.webroot

  detective = VersionDetective( args.url, settings )
  detective.analyse()

if __name__ == "__main__":
  main()

